{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb1634b-1ef2-4ffc-b29e-8c877e355de7",
   "metadata": {},
   "source": [
    "# GraphAI client\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to `graphai-client`. This package is designed to streamline programmatic interaction with the [GraphAI API](https://graphai.epfl.ch/), taking care of logins, authentication tokens, retries, and asynchronous as well as synchronous endpoints.\n",
    "\n",
    "This notebook will take you through a typical use case of the API through the client. Remember that in order to access any of the endpoints, you need to have a GraphAI account, which will give you access to some or all of the endpoint groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26504ba-4d0d-4e7a-9523-f766abd00c1c",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "### Installing the package\n",
    "\n",
    "Default installation:\n",
    "\n",
    "`pip install git+https://github.com/epflgraph/graphai-client.git`\n",
    "\n",
    "Editable installation (pip version >= 21.3):\n",
    "\n",
    "`pip install -e git+https://github.com/epflgraph/graphai-client.git`\n",
    "\n",
    "### Preparing to run this notebook\n",
    "\n",
    "In order to run this notebook, you need to have a GraphAI account. Create a `config` directory in the same directory as this notebook, create a `graphai-api.json` file within it, and set up its contents as follows:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"host\": \"https://graphai.epfl.ch\",\n",
    "  \"port\": 443,\n",
    "  \"user\": \"PUT_YOUR_USERNAME_HERE\",\n",
    "  \"password\": \"PUT_YOUR_PASSWORD_HERE\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5dc87e4-1a78-4835-b028-56c8cbca362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_path = 'config/graphai-api.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd05175-7b38-4acf-8e29-4444968e4d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphai_client.client import login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d8e071-b10d-4c39-938b-e1ca7b17b44d",
   "metadata": {},
   "source": [
    "## Use\n",
    "\n",
    "### Example 1: Translating text\n",
    "\n",
    "**This section requires your account to have access to the `translation` endpoints. If you encounter a permission error, contact the administrator.**\n",
    "\n",
    "Let's say you have some text in French that you want to translate to English. Before you get started, you need to log in using the `login` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b95a411-6573-40a3-9d9b-b4c9e06e4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "login_info = login(graph_api_json=credentials_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be0da78-2bae-492c-a07a-75f5f489806b",
   "metadata": {},
   "source": [
    "Now that you're logged in, let's discuss the translation function. The `graphai_client.client_api.translation.translate_text` function handles translation for you. All you need to provide are the text, the source and target languages, and the login info you just obtained.\n",
    "\n",
    "This function is part of the direct API functionalities, all of which are found in the `graphai_client.client_api` subpackage.\n",
    "\n",
    "At the time of this notebook's creation, the supported languages are EN-FR, FR-EN, IT-EN, and DE-EN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8419087-213b-4a1b-8baf-6697e4f32343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30m[2024-10-07 16:42:03] [GRAPHAI] [TRANSLATE] [PROCESSING] extracting en translation from fr text (44 characters)...\u001b[0m\n",
      "\u001b[32m[2024-10-07 16:42:03] [GRAPHAI] [TRANSLATE] [SUCCESS] en translation has been extracted from fr text (44 characters) (already done in the past)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from graphai_client.client_api.translation import translate_text\n",
    "french_text = \"Elle vend des coquillages au bord de la mer.\"\n",
    "translated_text = translate_text(text=french_text, source_language='fr', target_language='en', login_info=login_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b6d5831-8e66-4b16-a51e-669af64206f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' She sells shellfish by the sea.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416bcce-2382-414d-8e6b-24235857aba1",
   "metadata": {},
   "source": [
    "Not exactly \"she sells seashells by the seashore\", but close enough!\n",
    "\n",
    "Let's see another translation, this time from English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad584520-9fdb-44fb-b672-688bca26a352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30m[2024-10-07 16:42:03] [GRAPHAI] [TRANSLATE] [PROCESSING] extracting fr translation from en text (84 characters)...\u001b[0m\n",
      "\u001b[32m[2024-10-07 16:42:03] [GRAPHAI] [TRANSLATE] [SUCCESS] fr translation has been extracted from en text (84 characters) (already done in the past)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "english_text = \"I could make so many requests to the API and I still would not reach the rate limit.\"\n",
    "translated_text = translate_text(text=english_text, source_language='en', target_language='fr', login_info=login_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06e79dfa-b578-40d2-9138-8fecafcb1098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Je pourrais faire autant de demandes à l'API et je n'atteindrais toujours pas la limite de taux.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fdc25d-a5d2-47a7-8700-f493e1f8dac4",
   "metadata": {},
   "source": [
    "### Example 2: Processing a video\n",
    "\n",
    "**This section requires your account to have access to the `video`, `voice`, and `image` endpoints. If you encounter a permission error, contact the administrator.**\n",
    "\n",
    "Since video processing is the central functionality of GraphAI, `graphai-client` provides you with a singular function to directly and fully process a video: from downloading to slide and audio extraction and finally to OCR and audio transcription. This function is `graphai_client.client.process_video`.\n",
    "\n",
    "This function receives several flags and inputs. Some of the most important ones are:\n",
    "* `analyze_audio`: if set, the audio is extracted and transcribed. `True` by default.\n",
    "* `analyze_slides`: if set, slides are extracted and OCR is performed on them. You need to provide a Google API token for this endpoint to work. `True` by default.\n",
    "* `destination_languages`: list of languages to translate the results to. `['en', 'fr']` by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e525edd2-c752-45b8-8d05-987d43ff2caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30m[2024-10-07 16:42:03] [GRAPHAI] [DOWNLOAD VIDEO] [PROCESSING] extracting file from http://api.cast.switch.ch/p/113/sp/11300/serveFlavor/entryId/0_00gdquzv/v/2/ev/3/flavorId/0_i0v49s5y/forceproxy/true/name/a.mp4...\u001b[0m\n",
      "\u001b[32m[2024-10-07 16:42:11] [GRAPHAI] [DOWNLOAD VIDEO] [SUCCESS] file (0.8 MB) has been extracted from http://api.cast.switch.ch/p/113/sp/11300/serveFlavor/entryId/0_00gdquzv/v/2/ev/3/flavorId/0_i0v49s5y/forceproxy/true/name/a.mp4 (already done in the past) (all are active) (all are fingerprinted)\u001b[0m\n",
      "\u001b[30m[2024-10-07 16:42:11] [GRAPHAI] [EXTRACT AUDIO] [PROCESSING] extracting audio from 169770835520421902463099.mp4...\u001b[0m\n",
      "\u001b[32m[2024-10-07 16:42:12] [GRAPHAI] [EXTRACT AUDIO] [SUCCESS] audio has been extracted from 169770835520421902463099.mp4 (already done in the past) (all are active) (all are fingerprinted)\u001b[0m\n",
      "\u001b[30m[2024-10-07 16:42:12] [GRAPHAI] [AUDIO FINGERPRINT] [PROCESSING] extracting fingerprint from 169770835520421902463099.mp4_audio.ogg...\u001b[0m\n",
      "\u001b[32m[2024-10-07 16:42:12] [GRAPHAI] [AUDIO FINGERPRINT] [SUCCESS] fingerprint has been extracted from 169770835520421902463099.mp4_audio.ogg (already done in the past)\u001b[0m\n",
      "\u001b[30m[2024-10-07 16:42:12] [GRAPHAI] [TRANSCRIBE] [PROCESSING] extracting transcription from 169770835520421902463099.mp4_audio.ogg...\u001b[0m\n",
      "\u001b[32m[2024-10-07 16:42:12] [GRAPHAI] [TRANSCRIBE] [SUCCESS] 5 transcription has been extracted from 169770835520421902463099.mp4_audio.ogg (already done in the past)\u001b[0m\n",
      "\u001b[30m[2024-10-07 16:42:12] [GRAPHAI] [TRANSLATE] [5 SUBTITLES] [PROCESSING] extracting fr translation from en text (547 characters in 5 elements)...\u001b[0m\n",
      "\u001b[32m[2024-10-07 16:42:12] [GRAPHAI] [TRANSLATE] [5 SUBTITLES] [SUCCESS] 5 fr translation has been extracted from en text (547 characters in 5 elements) (already done in the past)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from graphai_client.client import process_video\n",
    "url= 'http://api.cast.switch.ch/p/113/sp/11300/serveFlavor/entryId/0_00gdquzv/v/2/ev/3/flavorId/0_i0v49s5y/forceproxy/true/name/a.mp4'\n",
    "# In order to enable slide analysis, provide your own Google Vision API token below.\n",
    "# We cannot provide our own since this notebook is publicly available.\n",
    "google_api_token = None\n",
    "video_info = process_video(url, analyze_slides=google_api_token is not None, login_info=login_info, google_api_token=google_api_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487449d9-202a-401b-b577-f73f911eb73f",
   "metadata": {},
   "source": [
    "Here we can see that the video was downloaded, its audio was extracted, and the subtitles were generated. The results also include a variety of information on the video and audio streams of the video file, plus the internal video and audio tokens. If you wish to further process the same file, you will have to use these tokens to refer to the file you have made prior requests for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e5bac3a-b5b8-4823-88b3-103fd93d6619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'http://api.cast.switch.ch/p/113/sp/11300/serveFlavor/entryId/0_00gdquzv/v/2/ev/3/flavorId/0_i0v49s5y/forceproxy/true/name/a.mp4',\n",
       " 'video_size': 881966,\n",
       " 'video_token': '169770835520421902463099.mp4',\n",
       " 'slides': None,\n",
       " 'slides_language': None,\n",
       " 'subtitles': [{'id': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 5.0,\n",
       "   'en': 'These subtitles have been generated automatically\\nBacteria GFP Expression',\n",
       "   'fr': 'Ces sous-titres ont été générés automatiquement\\nExpression des bactéries GFP'},\n",
       "  {'id': 1,\n",
       "   'start': 5.0,\n",
       "   'end': 17.0,\n",
       "   'en': 'The data consists of bacteria images acquired in face contrast and fluorescence across three different conditions, A, B, and C, with five replicates per condition.',\n",
       "   'fr': 'Les données consistent en des images de bactéries acquises en contraste facial et en fluorescence dans trois conditions différentes, A, B et C, avec cinq répétitions par condition.'},\n",
       "  {'id': 2,\n",
       "   'start': 17.0,\n",
       "   'end': 24.0,\n",
       "   'en': \"The fluorescent channel represents a GFP-tagged protein expressed in the bacteria's protoplasm.\",\n",
       "   'fr': 'Le canal fluorescent représente une protéine marquée GFP exprimée dans le protoplasme de la bactérie.'},\n",
       "  {'id': 3,\n",
       "   'start': 25.0,\n",
       "   'end': 31.0,\n",
       "   'en': 'Because the bacteria look quite separated, the experimenter would like to obtain per-bacteria measurements.',\n",
       "   'fr': \"Parce que les bactéries semblent assez séparées, l'expérimentateur aimerait obtenir des mesures par bactérie.\"},\n",
       "  {'id': 4,\n",
       "   'start': 31.0,\n",
       "   'end': 40.0,\n",
       "   'en': 'The experimenter is interested in fighting out if there is a significant change in the expression level of his fluorescent protein across the three conditions.',\n",
       "   'fr': \"L'expérimentateur est intéressé à se battre s'il y a un changement significatif dans le niveau d'expression de sa protéine fluorescente dans les trois conditions.\"}],\n",
       " 'audio_language': 'en',\n",
       " 'audio_fingerprint': '0c04140e08121e0a0008061e021a0c060a060418221c000a1e0e32220e142a1e_20_10',\n",
       " 'streams': [{'codec_type': 'audio',\n",
       "   'codec_name': 'aac',\n",
       "   'duration': 42.132993,\n",
       "   'bit_rate': 64404,\n",
       "   'sample_rate': 44100,\n",
       "   'resolution': None},\n",
       "  {'codec_type': 'video',\n",
       "   'codec_name': 'h264',\n",
       "   'duration': 42.233333,\n",
       "   'bit_rate': 95767,\n",
       "   'sample_rate': None,\n",
       "   'resolution': '640*360'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48429b69-ec94-4bb2-9434-afddeb3c1b83",
   "metadata": {},
   "source": [
    "### Example 3: Getting word embeddings for text\n",
    "\n",
    "**This section requires your account to have access to the `translation` endpoints. If you encounter a permission error, contact the administrator.**\n",
    "\n",
    "Another group of endpoints provided through the client is `embedding`, which allows you to embed a given text as a vector. Here's an example of how to use this functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c663900a-7088-4eab-8813-4553b28426ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30m[2024-10-07 16:42:12] [GRAPHAI] [EMBED] [PROCESSING] extracting embedding from text (68 characters)...\u001b[0m\n",
      "\u001b[32m[2024-10-07 16:42:13] [GRAPHAI] [EMBED] [SUCCESS] embedding has been extracted from text (68 characters) (already done in the past)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from graphai_client.client_api.embedding import embed_text\n",
    "text_to_embed = \"The Graph project at the Federal Institute of Technology in Lausanne\"\n",
    "result = embed_text(text_to_embed, login_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a0e602b-cb29-410b-8c41-2cd1d4fa9abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "result_vector = np.array(result)\n",
    "result_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78086e1f-840b-4233-a2c2-f01650066b81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
